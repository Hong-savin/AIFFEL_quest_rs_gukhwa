{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c40dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "0.5.2\n",
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "# 버전 확인 \n",
    "import os\n",
    "import pandas as pd\n",
    "import konlpy\n",
    "import gensim\n",
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "print(pd.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3992b62f",
   "metadata": {},
   "source": [
    "1) 데이터 준비 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4374a3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c8161a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150000, 3), (50000, 3))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9948522",
   "metadata": {},
   "source": [
    "2) 데이터 로더 구성\n",
    "\n",
    "- 중복 데이터 제거\n",
    "- NaN 결측치 제거\n",
    "- 한국어 토크나이저로 토큰화\n",
    "- 불용어(Stopwords) 제거\n",
    "- 사전 word_to_index 구성\n",
    "- 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "- X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa0c10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "# def (list_of_sentences):\n",
    "#     word_list = []\n",
    "#     for sentence in train_data['document']:\n",
    "#         temp = tokenizer.morphs(sentence)   # 토큰화\n",
    "#         temp = [word for word in temp if word not in stopwords]   # 불용어 제거\n",
    "#         word_list.append(temp)\n",
    "#     return word_list\n",
    "    \n",
    "\n",
    "def load_data(train_data, test_data, num_words):\n",
    "    \n",
    "    # 'document'열을 기준으로 중복 제거 후 train_data 데이터 대체\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how='any')    # NaN 제거\n",
    "\n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any')     \n",
    "    \n",
    "    \n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence)   # 토큰화\n",
    "        temp_X = [word for word in temp_X if word not in stopwords]   # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []    \n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence)   # 토큰화\n",
    "        temp_X = [word for word in temp_X if word not in stopwords]   # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "        \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000)\n",
    "    vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "    \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
    "            \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "        \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "      \n",
    "x_train, y_train, x_test, y_test, word_to_index = load_data(train_data, test_data, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8491d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0277764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      ".\n",
      "더 빙 . . 진짜 짜증 나 네요 목소리\n"
     ]
    }
   ],
   "source": [
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다.\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index[index_to_word[4]])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다.\n",
    "\n",
    "# 보정 후 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f96c7a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index[index_to_word[11]])  # 4 이 출력됩니다. \n",
    "print(index_to_word[11])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de1e31",
   "metadata": {},
   "source": [
    "3) 모델 구성을 위한 데이터 분석 및 가공\n",
    "\n",
    "- 데이터셋 내 문장 길이 분포\n",
    "- 적절한 최대 문장 길이 지정\n",
    "- keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96473ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트 데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 분포 (평균값, 최대값, 표준편차)를 계산\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29806abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41) (49157, 41)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045c619",
   "metadata": {},
   "source": [
    "4) 모델 구성 및 validation set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95b5e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_validation_set(x_train, y_train, num_of_validation):\n",
    "    \"\"\"\n",
    "    num_of_validation: validataion set 크기\n",
    "    \"\"\"\n",
    "    # validation set 10000건 분리\n",
    "    x_val = x_train[:num_of_validation]   \n",
    "    y_val = y_train[:num_of_validation]\n",
    "\n",
    "    # validation set을 제외한 나머지 15000건\n",
    "    partial_x_train = x_train[num_of_validation:]  \n",
    "    partial_y_train = y_train[num_of_validation:]\n",
    "\n",
    "    print(partial_x_train.shape)\n",
    "    print(partial_y_train.shape)\n",
    "    return partial_x_train, partial_y_train, x_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7fd2ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116182, 41)\n",
      "(116182,)\n"
     ]
    }
   ],
   "source": [
    "# 검증 세트 구성\n",
    "\n",
    "N = 30000   # 검증세트 크기\n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "partial_x_train, partial_y_train, x_val, y_val = split_validation_set(x_train, y_train, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8df184f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 41)          410205    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 1600      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 411,886\n",
      "Trainable params: 411,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "word_vector_dim = maxlen    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "# embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# # 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "# raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "# output = embedding(raw_inputs)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "974cad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "286/286 [==============================] - 6s 7ms/step - loss: 0.4513 - accuracy: 0.8086 - val_loss: 0.3213 - val_accuracy: 0.8682\n",
      "Epoch 2/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.3292 - accuracy: 0.8604 - val_loss: 0.2928 - val_accuracy: 0.8798\n",
      "Epoch 3/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.3072 - accuracy: 0.8699 - val_loss: 0.2771 - val_accuracy: 0.8847\n",
      "Epoch 4/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.2925 - accuracy: 0.8761 - val_loss: 0.2686 - val_accuracy: 0.8885\n",
      "Epoch 5/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.2792 - accuracy: 0.8816 - val_loss: 0.2568 - val_accuracy: 0.8943\n",
      "Epoch 6/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.2652 - accuracy: 0.8876 - val_loss: 0.2367 - val_accuracy: 0.9034\n",
      "Epoch 7/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.2505 - accuracy: 0.8943 - val_loss: 0.2241 - val_accuracy: 0.9101\n",
      "Epoch 8/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.2360 - accuracy: 0.9012 - val_loss: 0.2100 - val_accuracy: 0.9155\n",
      "Epoch 9/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.2222 - accuracy: 0.9083 - val_loss: 0.2041 - val_accuracy: 0.9199\n",
      "Epoch 10/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.2108 - accuracy: 0.9138 - val_loss: 0.1885 - val_accuracy: 0.9255\n",
      "Epoch 11/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.2005 - accuracy: 0.9190 - val_loss: 0.1759 - val_accuracy: 0.9313\n",
      "Epoch 12/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.1909 - accuracy: 0.9238 - val_loss: 0.1676 - val_accuracy: 0.9360\n",
      "Epoch 13/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.1821 - accuracy: 0.9280 - val_loss: 0.1613 - val_accuracy: 0.9391\n",
      "Epoch 14/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.1738 - accuracy: 0.9316 - val_loss: 0.1598 - val_accuracy: 0.9399\n",
      "Epoch 15/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.1674 - accuracy: 0.9354 - val_loss: 0.1477 - val_accuracy: 0.9466\n",
      "Epoch 16/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.1574 - accuracy: 0.9400 - val_loss: 0.1373 - val_accuracy: 0.9508\n",
      "Epoch 17/20\n",
      "286/286 [==============================] - 2s 5ms/step - loss: 0.1512 - accuracy: 0.9428 - val_loss: 0.1347 - val_accuracy: 0.9515\n",
      "Epoch 18/20\n",
      "286/286 [==============================] - 2s 5ms/step - loss: 0.1449 - accuracy: 0.9456 - val_loss: 0.1279 - val_accuracy: 0.9546\n",
      "Epoch 19/20\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.1417 - accuracy: 0.9472 - val_loss: 0.1252 - val_accuracy: 0.9565\n",
      "Epoch 20/20\n",
      "286/286 [==============================] - 2s 5ms/step - loss: 0.1344 - accuracy: 0.9504 - val_loss: 0.1190 - val_accuracy: 0.9588\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "500a3329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.5426 - accuracy: 0.8366\n",
      "[0.5426317453384399, 0.8366051912307739]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8926e06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304be252",
   "metadata": {},
   "source": [
    "6) 손실, 정확도 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79e2b10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def draw_graph(history_dict):\n",
    "    acc = history_dict['accuracy']\n",
    "    val_acc = history_dict['val_accuracy']\n",
    "    loss = history_dict['loss']\n",
    "    val_loss = history_dict['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # \"bo\"는 \"파란색 점\"입니다\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    # b는 \"파란 실선\"입니다\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "draw_graph(history_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d6307656",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/aiffelword2vec_ko.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54/1868996090.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mword2vec_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'word2vec_ko.model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# limit = None으로 하면 워드 벡터에 있는 모든 단어(300만개) 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"끝\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# vector     # 무려 300dim의 워드 벡터입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \"\"\"\n\u001b[0;32m-> 1459\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/aiffelword2vec_ko.model'"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'word2vec_ko.model'\n",
    "# limit = None으로 하면 워드 벡터에 있는 모든 단어(300만개) 사용\n",
    "word_vectors = Word2VecKeyedVectors.load(word2vec_path)\n",
    "vector = word_vectors.wv[\"끝\"]\n",
    "# vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2327cf2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KeyedVectors' object has no attribute 'wv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54/1896808097.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mindex_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyedVectors' object has no attribute 'wv'"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec.wv:\n",
    "        embedding_matrix[i] = word2vec.wv[index_to_word[i]]\n",
    "        \n",
    "embedding_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac44805b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02368164,  0.10791016, -0.13574219, -0.20605469, -0.02270508,\n",
       "        0.08349609,  0.0177002 , -0.17578125,  0.0123291 ,  0.28515625,\n",
       "       -0.19140625, -0.33789062, -0.07910156, -0.03295898, -0.00485229,\n",
       "        0.06079102,  0.18457031,  0.27734375, -0.22949219,  0.02600098,\n",
       "       -0.0378418 , -0.24511719,  0.42382812, -0.03759766, -0.32421875,\n",
       "        0.13085938, -0.3046875 , -0.00897217, -0.06445312,  0.06445312,\n",
       "       -0.04931641, -0.02954102, -0.33984375, -0.51953125, -0.16992188,\n",
       "       -0.11767578, -0.2734375 ,  0.27929688, -0.01623535,  0.09277344,\n",
       "       -0.07714844, -0.23535156, -0.03613281,  0.16308594,  0.32421875,\n",
       "        0.08398438, -0.11572266, -0.28125   , -0.12207031, -0.06689453,\n",
       "        0.21679688,  0.12158203, -0.00994873,  0.00166321, -0.04931641,\n",
       "       -0.006073  , -0.2734375 , -0.02526855, -0.04150391, -0.18652344,\n",
       "       -0.0402832 ,  0.17578125, -0.16699219, -0.06054688, -0.15917969,\n",
       "       -0.04858398,  0.11914062,  0.04614258,  0.01843262, -0.01586914,\n",
       "        0.33203125,  0.06396484, -0.11767578, -0.16796875,  0.078125  ,\n",
       "        0.14941406,  0.10986328, -0.29492188, -0.38476562,  0.0402832 ,\n",
       "       -0.203125  , -0.12060547,  0.24804688, -0.28515625,  0.19140625,\n",
       "        0.06835938, -0.08984375,  0.29882812,  0.16015625, -0.1328125 ,\n",
       "       -0.09619141,  0.10546875, -0.14257812, -0.04907227, -0.05737305,\n",
       "       -0.02172852, -0.3046875 ,  0.0703125 ,  0.42382812, -0.03442383,\n",
       "       -0.00100708,  0.00078583,  0.21777344, -0.30273438, -0.02661133,\n",
       "        0.33789062, -0.14355469, -0.01855469, -0.30859375, -0.0612793 ,\n",
       "       -0.29101562,  0.02526855,  0.05322266, -0.3671875 ,  0.43164062,\n",
       "        0.19726562,  0.07763672, -0.06201172, -0.08984375, -0.13574219,\n",
       "        0.07861328, -0.26171875, -0.21386719,  0.01055908, -0.08740234,\n",
       "       -0.06176758, -0.24023438,  0.10546875,  0.09082031,  0.24707031,\n",
       "       -0.02758789,  0.15429688,  0.34960938,  0.04760742, -0.27539062,\n",
       "       -0.04956055, -0.05761719, -0.14746094,  0.27929688, -0.17089844,\n",
       "        0.14257812, -0.07763672,  0.03076172, -0.2578125 , -0.44921875,\n",
       "       -0.15527344, -0.00457764,  0.53515625, -0.12792969, -0.11132812,\n",
       "       -0.125     , -0.4296875 ,  0.08007812, -0.07421875,  0.11132812,\n",
       "       -0.41601562, -0.06396484, -0.00156403, -0.24511719, -0.12597656,\n",
       "        0.05078125,  0.04125977, -0.05688477, -0.25390625, -0.19335938,\n",
       "       -0.109375  ,  0.13183594,  0.12597656, -0.07275391,  0.23535156,\n",
       "       -0.23144531, -0.45898438, -0.11767578,  0.00921631,  0.18847656,\n",
       "        0.1640625 ,  0.42382812, -0.11328125, -0.16308594,  0.12695312,\n",
       "       -0.27148438,  0.29882812,  0.00082779, -0.09619141, -0.28710938,\n",
       "       -0.21679688,  0.08642578,  0.15332031, -0.00823975, -0.09472656,\n",
       "       -0.06494141,  0.10009766, -0.27148438, -0.06591797,  0.15722656,\n",
       "        0.2109375 , -0.04101562,  0.03051758,  0.1171875 , -0.09716797,\n",
       "       -0.31445312, -0.07714844, -0.3046875 , -0.29882812,  0.09375   ,\n",
       "       -0.11376953, -0.09667969, -0.15332031,  0.10351562,  0.28320312,\n",
       "        0.26367188, -0.03491211,  0.11474609, -0.18457031, -0.04711914,\n",
       "        0.10058594, -0.13476562,  0.25      , -0.16210938,  0.06542969,\n",
       "        0.06494141, -0.00762939,  0.31640625, -0.04516602,  0.06835938,\n",
       "        0.16894531,  0.2265625 ,  0.09570312, -0.13476562, -0.21484375,\n",
       "        0.12207031, -0.18261719, -0.11181641, -0.26171875, -0.0559082 ,\n",
       "       -0.0859375 ,  0.15917969, -0.07373047,  0.03088379,  0.07470703,\n",
       "        0.06933594,  0.46484375,  0.296875  ,  0.36523438, -0.05883789,\n",
       "        0.26171875, -0.29492188,  0.40820312, -0.04711914, -0.47265625,\n",
       "        0.17285156,  0.359375  ,  0.13183594,  0.203125  ,  0.06494141,\n",
       "        0.12060547, -0.07714844,  0.08300781,  0.06347656,  0.0859375 ,\n",
       "        0.00576782, -0.07373047,  0.2578125 ,  0.07519531,  0.27734375,\n",
       "        0.33007812,  0.02600098,  0.08447266,  0.00457764, -0.1796875 ,\n",
       "        0.06933594, -0.2734375 ,  0.27734375, -0.24023438,  0.07666016,\n",
       "        0.11669922, -0.08105469, -0.08496094, -0.01831055,  0.171875  ,\n",
       "        0.03588867,  0.12695312, -0.11474609,  0.00234985,  0.26757812,\n",
       "        0.00285339, -0.08642578, -0.13574219, -0.08544922,  0.22753906,\n",
       "       -0.16015625,  0.09960938,  0.1484375 ,  0.08154297,  0.09521484,\n",
       "       -0.42578125, -0.15722656, -0.21386719, -0.08251953, -0.0168457 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdb3fdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a792ba72",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5426082a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 3s 83ms/step - loss: 0.6993 - accuracy: 0.5021 - val_loss: 0.6930 - val_accuracy: 0.5334\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.6859 - accuracy: 0.5518 - val_loss: 0.6828 - val_accuracy: 0.5692\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.6659 - accuracy: 0.6045 - val_loss: 0.6657 - val_accuracy: 0.5918\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.6036 - accuracy: 0.7077 - val_loss: 0.5694 - val_accuracy: 0.7460\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.4498 - accuracy: 0.8247 - val_loss: 0.4359 - val_accuracy: 0.8034\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.3082 - accuracy: 0.8834 - val_loss: 0.3822 - val_accuracy: 0.8274\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.2213 - accuracy: 0.9216 - val_loss: 0.3359 - val_accuracy: 0.8586\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.1600 - accuracy: 0.9536 - val_loss: 0.3295 - val_accuracy: 0.8638\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.1191 - accuracy: 0.9695 - val_loss: 0.3365 - val_accuracy: 0.8643\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0857 - accuracy: 0.9826 - val_loss: 0.3495 - val_accuracy: 0.8622\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0671 - accuracy: 0.9885 - val_loss: 0.3684 - val_accuracy: 0.8616\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0432 - accuracy: 0.9953 - val_loss: 0.3792 - val_accuracy: 0.8609\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0311 - accuracy: 0.9979 - val_loss: 0.3928 - val_accuracy: 0.8615\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0230 - accuracy: 0.9985 - val_loss: 0.4074 - val_accuracy: 0.8621\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0170 - accuracy: 0.9990 - val_loss: 0.4230 - val_accuracy: 0.8627\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0129 - accuracy: 0.9994 - val_loss: 0.4362 - val_accuracy: 0.8615\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0107 - accuracy: 0.9996 - val_loss: 0.4506 - val_accuracy: 0.8601\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0083 - accuracy: 0.9997 - val_loss: 0.5242 - val_accuracy: 0.8593\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.5501 - val_accuracy: 0.8597\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.5641 - val_accuracy: 0.8598\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f74bd7d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.6300 - accuracy: 0.8438\n",
      "[0.6299698948860168, 0.8438000082969666]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "# 782/782 - 2s - loss: 0.6300 - accuracy: 0.8438\n",
    "\n",
    "history_dict = history.history\n",
    "# print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "# dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "516314b9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
